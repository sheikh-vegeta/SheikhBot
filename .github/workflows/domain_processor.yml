name: Domain Processing and Dataset Creation

on:
  schedule:
    - cron: '0 */12 * * *'
  workflow_dispatch:
  
env:
  DATASET_REPO: "sheikh-vegeta/domain-intelligence"
  MODEL_REPO: "sheikh-vegeta/SheikhLLMa"

jobs:
  process-domains:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - uses: actions/checkout@v3
      
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            ~/.cache/huggingface
          key: ${{ runner.os }}-deps-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-deps-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy==1.23.5 pandas==1.5.3 python-whois dnspython
          pip install -r requirements.txt
          pip install datasets transformers huggingface_hub spacy
          python -m spacy download en_core_web_sm

      - name: Process domains
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        run: |
          python scripts/domain_processor/fetch_domains.py
          python scripts/domain_processor/analyze_domains.py
        continue-on-error: true

      - name: Create dataset
        if: always()
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        run: python scripts/domain_processor/create_dataset.py

      - name: Train model
        if: success()
        env:
          HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        run: python scripts/domain_processor/train_model.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: process-artifacts
          path: |
            logs/**
            data/**
            models/**
          retention-days: 5
          if-no-files-found: warn
