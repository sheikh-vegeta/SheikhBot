name: Domain Processing and Dataset Creation

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  DATASET_REPO: "sheikh-vegeta/domain-intelligence"
  MODEL_REPO: "sheikh-vegeta/SheikhLLMa"

jobs:
  process-domains:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install datasets transformers huggingface_hub
          
      - name: Fetch Domain Data
        run: |
          python scripts/domain_processor/fetch_domains.py
          
      - name: Process and Analyze Domains
        run: |
          python scripts/domain_processor/analyze_domains.py
          
      - name: Create HuggingFace Dataset
        run: |
          python scripts/domain_processor/create_dataset.py
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          
      - name: Train Model
        if: success()
        run: |
          python scripts/domain_processor/train_model.py
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
